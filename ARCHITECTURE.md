# Hartonomous Architecture

**Database-First Autonomous AI Platform**

## Overview

Hartonomous runs the entire autonomous AI loop inside SQL Server 2025. The database is the runtime, storage substrate, and intelligence layer. Stored procedures execute the OODA loop (Observe → Orient → Decide → Act), CLR functions provide SIMD-accelerated vector operations and transformer inference, and .NET 10 services orchestrate ingestion, expose REST APIs, and sync provenance to Neo4j.

**Core Principle**: The database is not a passive store—it is the active AI runtime. T-SQL is the AI interface. Model weights, embeddings, and provenance live in SQL tables with geometry projections, temporal history, and graph relationships.

**Architecture Philosophy**: **Database-First**. SQL Server Database Project (`sql/` directory) owns all schema (tables, stored procedures, functions, CLR bindings). EF Core (`src/Hartonomous.Data`) is used only as an ORM for data access—it does **not** control schema. Applications (`Hartonomous.Api`, `Hartonomous.Admin`, workers) are thin clients that orchestrate database intelligence and expose external interfaces.

## Platform Components

### 1. Database Substrate (SQL Server 2025)

**Unified Atom Store**: `dbo.Atoms` (`sql/tables/dbo.Atoms.sql`) is the canonical multimodal data record. Each atom has:

- `Modality` (text, image, audio, video, sensor, graph)
- `ContentJson` (JSON descriptor/payload)
- `SpatialKey` (`GEOMETRY`) for spatial indexing
- `TemporalMetadata` for temporal tracking
- EF Core mapping in `src/Hartonomous.Data/Configurations/AtomConfiguration.cs`

**Embeddings**: `dbo.AtomEmbeddings` (`sql/tables/dbo.AtomEmbeddings.sql`) stores:

- `EmbeddingVector` (`VECTOR(1998)`) for native vector operations
- `SpatialGeometry` and `SpatialCoarse` (`GEOMETRY`) for R-tree spatial indexing
- Generated by C# `EmbeddingService` (HTTP ingestion) or CLR `fn_ComputeEmbedding` (T-SQL embedding)
- Spatial indexes created by `sql/procedures/Common.CreateSpatialIndexes.sql`

**Model Decomposition**: `dbo.Models`, `dbo.ModelLayers`, `dbo.TensorAtoms`, `dbo.TensorAtomCoefficients`:

- Models are factored into reusable tensor slices
- `TensorAtomCoefficients_Temporal.sql` tracks weights with system-versioned temporal history
- Each tensor has `SpatialSignature` (`GEOMETRY`) for similarity search across model space
- EF configurations: `TensorAtomConfiguration.cs`, `TensorAtomCoefficientConfiguration.cs`, `LayerTensorSegmentConfiguration.cs`

**Dual-Ledger Provenance**:

- **SQL Temporal Tables**: System-versioned history on `TensorAtomCoefficients`, `Weights`, and other critical tables. Enables point-in-time queries for compliance (`SELECT * FROM TensorAtomCoefficients FOR SYSTEM_TIME AS OF '2024-01-01'`).
- **SQL Graph Tables**: `graph.AtomGraphNodes.sql`, `graph.AtomGraphEdges.sql` capture causal relationships using SQL Server graph syntax (`MATCH (a)-[e]->(b)`).
- **Neo4j Provenance Graph**: **CRITICAL FOR AUDITABILITY**. Service Broker→Neo4j worker (`Hartonomous.Workers.Neo4jSync`) mirrors inference traces, model evolution, reasoning paths to Neo4j for explainability queries.
  - **Schema**: `neo4j/schemas/CoreSchema.cypher` defines nodes (`:Inference`, `:Model`, `:Decision`, `:Evidence`, `:Alternative`, `:ReasoningMode`) and relationships (`[:USED_MODEL]`, `:RESULTED_IN`, `:SUPPORTED_BY`, `:CONSIDERED_ALTERNATIVE`)
  - **Sync Mechanism**: SQL Server Service Broker queue (`Neo4jSyncQueue`) triggers on inference completion → `sp_ForwardToNeo4j_Activated` enqueues sync message → `Hartonomous.Workers.Neo4jSync` consumes and executes Cypher
  - **Explainability Queries**: "Why was this decision made?", "Which models contributed most?", "What alternatives were considered?", "What evidence supports this?", "How have models evolved?" (see query patterns in `CoreSchema.cypher`)
  - **Regulatory Compliance**: Full audit trail for AI decisions required by GDPR Article 22 (right to explanation), EU AI Act transparency requirements, financial services regulations (SR 11-7)
  - **Worker Implementation**: `ProvenanceGraphBuilder` (`src/Hartonomous.Workers.Neo4jSync/Services/ProvenanceGraphBuilder.cs`) constructs Cypher queries from SQL events

### 2. CLR Intelligence Layer (SqlClrFunctions)

**Assembly**: `src/SqlClr/SqlClrFunctions.csproj` compiles to `SqlClrFunctions.dll` targeting .NET Framework 4.8.1. Deployed via `scripts/deploy-database-unified.ps1` or `sql/procedures/Common.ClrBindings.sql`.

**Security Model**: CLR assemblies are deployed with minimum required permissions:

- **SAFE**: Deterministic functions without external resource access (preferred where possible)
- **UNSAFE**: Required for SIMD intrinsics (`System.Runtime.Intrinsics`), file I/O (FILESTREAM), and unmanaged memory operations
  - Registered via `sp_add_trusted_assembly` (assembly hash whitelisting)
  - Database property `TRUSTWORTHY OFF` (never enable `TRUSTWORTHY` for security)
  - Requires `sysadmin` or `CONTROL SERVER` for deployment
  - See [scripts/CLR_SECURITY_ANALYSIS.md](../scripts/CLR_SECURITY_ANALYSIS.md) for security surface analysis

**Permission Set Rationale**:

- Vector operations (`VectorOperations.cs`, `VectorAggregates.cs`): `UNSAFE` (SIMD intrinsics via `System.Runtime.Intrinsics.X86.Avx2`)
- Transformer inference (`TransformerInference.cs`): `UNSAFE` (SIMD + unmanaged memory allocation)
- FILESTREAM operations: `UNSAFE` (file system access)
- Pure math/statistical functions: `SAFE` (no external dependencies)

**Vector Analytics**:

- `VectorAggregates.cs`, `AdvancedVectorAggregates.cs`: SIMD-accelerated vector aggregates (mean, covariance, correlation)
- `TimeSeriesVectorAggregates.cs`: Time-series vector operations
- `VectorOperations.cs`: Core SIMD operations (dot product, cosine similarity, Euclidean distance)
- Invoked by `sql/procedures/Functions.*` and `Inference.VectorSearchSuite.sql`

**Transformer Inference**:

- `TensorOperations/TransformerInference.cs`: Multi-head attention, feed-forward layers
- `AttentionGeneration.cs`: Scaled dot-product attention
- `NeuralVectorAggregates.cs`: Neural network primitives
- Called from inference pipelines and autonomous reasoning procedures

**Anomaly Detection**:

- `AnomalyDetectionAggregates.cs`: Isolation Forest, Mahalanobis distance, threshold-based anomaly scores
- Feeds reflex governance and OODA loop triggers

**Multimodal Processing**:

- `AudioProcessing.cs`, `ImageProcessing.cs`, `MultiModalGeneration.cs`: Domain-specific processing
- Called from `clr_RunInference` and `fn_GenerateText`

**Spatial Utilities**:

- `SpatialOperations.cs`, `Core/LandmarkProjection.cs`: Trilateration projection (high-dimensional → 3D geometry)
- Enables R-tree spatial indexing on embeddings and tensor atoms
- Aligns with NetTopologySuite geometry columns in EF Core

**Event Streams**:

- `AtomicStream.cs`, `ComponentStream.cs`, `StreamOrchestrator.cs`: SQL CLR UDTs for domain event serialization
- Consumed by `provenance.AtomicStreamFactory.sql` and `Stream.StreamOrchestration.sql`

### 3. Autonomous OODA Loop

**Service Broker Infrastructure**: `scripts/setup-service-broker.sql` creates:

- Message types, contracts, services
- Queues: `AnalyzeQueue`, `HypothesizeQueue`, `ActQueue`, `LearnQueue`
- Activation procedures for asynchronous processing

**Four-Phase Loop**:

1. **Analyze** (`sql/procedures/dbo.sp_Analyze.sql`):
   - Receives observations (slow queries, anomalies, telemetry)
   - Aggregates data using CLR helpers (`QueryStoreAnalyzer.cs`, `AnomalyDetectionAggregates.cs`)
   - Publishes `AnalyzeMessage` to Service Broker

2. **Hypothesize** (`sql/procedures/dbo.sp_Hypothesize.sql`):
   - Consumes analysis messages
   - Evaluates patterns, anomaly counts
   - Generates structured hypotheses (index creation, cache warming, weight adjustments)
   - Publishes hypotheses to `ActQueue`

3. **Act** (`sql/procedures/dbo.sp_Act.sql`):
   - Executes recommended actions (create index, adjust weights via `Feedback.ModelWeightUpdates.sql`, run maintenance)
   - Actions run in transactions for safety
   - Publishes results to `LearnQueue`

4. **Learn** (`sql/procedures/dbo.sp_Learn.sql`):
   - Evaluates action outcomes
   - Records results in `dbo.AutonomousImprovementHistory`
   - Loops new observations back into `AnalyzeQueue`

**Event Handlers**: `src/Hartonomous.Infrastructure/Messaging/Handlers/OodaEventHandlers.cs` logs and routes OODA events from in-memory event bus. Long-running execution happens via SQL stored procedures and Service Broker.

### 4. .NET 10 Orchestration Layer

**API Server** (`src/Hartonomous.Api`):

- ASP.NET Core 10 REST API gateway
- `Program.cs` configures:
  - Azure AD JWT authentication (tenant-aware authorization)
  - Role hierarchy policies (`Hartonomous.Api.Authorization`)
  - Rate limiting (`Hartonomous.Infrastructure.RateLimiting`)
  - OpenTelemetry tracing/metrics (OTLP export)
- Controllers expose:
  - Ingestion (`/api/atoms/ingest`)
  - Inference (`/api/inference`)
  - Search (`/api/search`)
  - Provenance (`/api/provenance`)
  - Operations/admin (`/api/operations`, `/api/admin`)

**Admin Portal** (`src/Hartonomous.Admin`):

- Blazor Server application
- Telemetry dashboards (`Services/TelemetryService.cs`, `Operations/TelemetryOperations.cs`)
- Atom browser, model management UI
- SignalR hub (`Hubs/TelemetryHub.cs`) for real-time telemetry streaming
- Shares infrastructure registrations (`AddHartonomousHealthChecks`, `AddPrometheusExporter`)

**Background Workers**:

- **CES Consumer** (`src/Hartonomous.Workers.CesConsumer`):
  - Processes SQL Server 2025 Change Event Stream (CDC)
  - `CesConsumerService` reads CDC payloads
  - `CdcEventMapper` maps to domain events
  - `FileCdcCheckpointManager` tracks ingestion progress

- **Neo4j Sync** (`src/Hartonomous.Workers.Neo4jSync`):
  - **Purpose**: **CRITICAL FOR AUDITABILITY** - Mirrors SQL provenance to Neo4j for explainability queries and regulatory compliance
  - `ServiceBrokerMessagePump` consumes Service Broker messages from `Neo4jSyncQueue`
  - Coordinates with retry/circuit breaker policies (`Hartonomous.Infrastructure.Resilience`)
  - `ProvenanceGraphBuilder` projects weight-update events into Neo4j:
    - `:Inference` nodes with task type, confidence, duration, prompt
    - `:Model` nodes with contribution weights, individual confidence
    - `:Decision` nodes with output, confidence, token count
    - `:Evidence` nodes with similarity scores, sources, content
    - `:Alternative` nodes with rejected paths and reasons
    - `:ReasoningMode` nodes (vector similarity, spatial query, graph traversal, symbolic logic)
    - Relationships: `[:USED_MODEL]`, `[:RESULTED_IN]`, `[:SUPPORTED_BY]`, `[:CONSIDERED_ALTERNATIVE]`, `[:INFLUENCED]`, `[:RATED_BY]`
  - Synchronizes SQL temporal history with Neo4j graph provenance
  - **Compliance**: Enables GDPR Article 22 "right to explanation", EU AI Act transparency, financial services AI audit requirements

- **Infrastructure Hosted Services** (`src/Hartonomous.Infrastructure`):
  - `AtomIngestionWorker`, `InferenceJobWorker`: Keep pipelines active
  - Event-bus hosted service: Coordinates in-memory domain events

### 5. Domain and Infrastructure Services

**Core Domain** (`src/Hartonomous.Core`):

- Entities: `Atom`, `AtomEmbedding`, `TensorAtom`, `TensorAtomCoefficient`, `Model`, `ModelLayer`
- Value objects, interfaces, domain events
- Pure domain logic, no infrastructure dependencies

**Shared Contracts** (`src/Hartonomous.Shared.Contracts`):

- DTOs, request/response models
- Shared across API, Admin, Workers

**Data Layer** (`src/Hartonomous.Data`):

- EF Core 10 `DbContext`
- **Database-First Design**: EF Core configurations map to SQL schema owned by SQL Server Database Project
- Entity configurations (`Configurations/*.cs`) wire:
  - Geometry columns (`SpatialKey`, `SpatialSignature`) using NetTopologySuite
  - JSON columns (`ContentJson`, `DescriptorJson`) using JSON serialization
  - Temporal tables (system-versioned history) with `ToTable(t => t.IsTemporal())`
  - Graph relationships (`Model → ModelLayer → TensorAtom → TensorAtomCoefficient`)
- **No migrations control schema**: Migrations exist for backward compatibility but schema changes happen in `sql/` scripts
- Scaffolding: Use `dotnet ef dbcontext scaffold` to generate entities from deployed database when schema changes
- Manual configuration updates required after SQL schema modifications

**Infrastructure** (`src/Hartonomous.Infrastructure`):

- **DI Registration** (`DependencyInjection.cs`): Central registration for database access, Service Broker messaging, billing, security, resilience
- **Pipelines**:
  - `Pipelines/IngestionPipeline.cs`: Multi-stage ingestion (validation → embedding → persistence → provenance)
  - `Pipelines/InferencePipeline.cs`: Inference orchestration (retrieval → reasoning → generation → billing)
  - `Pipelines/ProvenancePipeline.cs`: Lineage capture and graph sync
- **AI Services**:
  - `AI/Embeddings/EmbeddingService.cs`: C# embedding generation for HTTP ingestion
  - `AI/Inference/InferenceService.cs`: Inference orchestration
  - `AI/ModelManagement/ModelRegistry.cs`: Model lifecycle management
- **Messaging**:
  - `Messaging/EventBus.cs`: In-memory domain event bus
  - `Messaging/ServiceBrokerClient.cs`: Service Broker integration
  - `Messaging/Handlers/OodaEventHandlers.cs`: OODA event routing
- **Resilience**: `Resilience/ResiliencePolicies.cs` defines retry, circuit breaker, timeout policies
- **Billing**: `Billing/BillingService.cs`, `Billing/UsageTracker.cs` track inference costs
- **Security**: Tenant isolation, authorization handlers, rate limiting strategies

## Dual Embedding Paths

Hartonomous supports two embedding generation paths to serve different workflows:

### Path 1: C# EmbeddingService (HTTP Ingestion)

**When**: External clients POST multimodal data via REST API

**Flow**:

1. Client POSTs atom data to `/api/atoms/ingest`
2. `IngestionController` validates, enqueues to `IngestionPipeline`
3. `EmbeddingService.GenerateEmbeddingAsync()` calls:
   - Azure OpenAI API (text, multimodal)
   - Local ONNX models (optional)
   - Custom embedding providers
4. Result persisted to `dbo.AtomEmbeddings` via EF Core
5. Spatial indexes automatically updated

**Implementation**: `src/Hartonomous.Infrastructure/AI/Embeddings/EmbeddingService.cs`

### Path 2: CLR fn_ComputeEmbedding (T-SQL Embedding)

**When**: Autonomous agents, scheduled jobs, or ad-hoc T-SQL queries need embeddings

**Flow**:

1. T-SQL invokes `dbo.fn_ComputeEmbedding(@text, @modelName)`
2. CLR function loads model weights from FILESTREAM
3. BPE tokenization via bridge library
4. Transformer inference via `TransformerInference.cs`
5. Returns `VECTOR(1998)` directly to SQL
6. Caller can `INSERT` into `dbo.AtomEmbeddings` or use inline

**Example**:

```sql
DECLARE @embedding VECTOR(1998);
SET @embedding = dbo.fn_ComputeEmbedding('autonomous agent observation', 'text-embedding-3-large');

-- Use in WHERE clause immediately
SELECT TOP 10 AtomId, Modality
FROM dbo.AtomEmbeddings
ORDER BY dbo.clr_VectorDistance(@embedding, EmbeddingVector) ASC;
```

**Advantages**: Sub-millisecond latency (no HTTP round-trip), full ACID semantics, embeds autonomous reasoning directly in T-SQL

## Database-First Design Philosophy

### Why SQL Server as AI Runtime?

1. **Transactional Semantics**: Inference + billing + provenance in one ACID transaction. No eventual consistency, no distributed transactions.
2. **Mature Tooling**: DBAs already know how to manage, monitor, backup, secure, tune SQL Server. No new operational burden.
3. **Spatial Indexes**: R-tree provides O(log n) nearest-neighbor search without external vector database.
4. **Graph Queries**: Built-in `MATCH` syntax for provenance traversal. No separate graph database.
5. **Temporal Tables**: Point-in-time queries for compliance, audit, and time-travel debugging.
6. **Service Broker**: Message queue with ACID guarantees. No external Kafka/RabbitMQ.
7. **CLR Integration**: SIMD-accelerated custom functions in-process. No microservice latency.

### Why GEOMETRY for Embeddings?

`VECTOR(1998)` type has dimension limit. GEOMETRY overcomes this:

- **Trilateration Projection**: High-dimensional embeddings (e.g., 4096D) projected to 3D via distance-preserving transformation
- **Spatial Indexes**: R-tree enables O(log n) spatial queries (bounding box filter → exact distance refinement)
- **Cross-Domain Joins**: Spatial joins between embeddings and geospatial data
- **Unlimited Dimensions**: No hard cap (VECTOR limited to 1998 dimensions)

### Why CLR Instead of External Services?

1. **Latency**: Sub-millisecond vs. network round-trip (10-100ms)
2. **Consistency**: ACID transactions. No distributed transaction coordinator.
3. **Deployment**: One database, not N microservices
4. **Security**: Data never leaves SQL Server boundary. Simplified attack surface.
5. **Licensing**: No per-inference API charges. Inference cost = CPU time.

### Why Service Broker for OODA?

1. **ACID Guarantees**: Autonomous actions in transactions. Rollback on failure.
2. **Poison Message Handling**: Failed hypotheses don't crash system. Auto-retry with backoff.
3. **Ordered Execution**: Conversation groups ensure correct sequencing.
4. **No External Dependencies**: Built into SQL Server. Zero-configuration messaging.

### Why Neo4j for Provenance? (Auditability & Explainability)

**Regulatory Drivers**:

- **GDPR Article 22**: Right to explanation for automated decision-making
- **EU AI Act**: Transparency requirements for high-risk AI systems
- **Financial Services**: SR 11-7 (model risk management), BCBS 239 (risk data aggregation)
- **Healthcare**: HIPAA audit trails, FDA software validation requirements

**Technical Advantages**:

1. **Graph Query Performance**: O(1) relationship traversal vs O(n) SQL joins for multi-hop lineage queries
2. **Temporal Reasoning**: "What prior inferences influenced this decision?" requires recursive graph traversal (inefficient in SQL)
3. **Counterfactual Analysis**: "What if we had used model B instead of A?" requires graph pattern matching across alternative paths
4. **Model Evolution Tracking**: `(:ModelVersion)-[:EVOLVED_TO*]->(:ModelVersion)` captures causal chain of model improvements
5. **Explainability Patterns**: Pre-defined Cypher queries answer "Why?", "What if?", "When?", "How confident?" questions required by regulators

**Architecture**:

- **Dual Write**: SQL temporal tables (compliance/audit) + Neo4j graph (explainability/analysis)
- **Eventual Consistency**: Service Broker ensures Neo4j sync completes (retry on failure, circuit breaker on Neo4j unavailable)
- **Schema**: `neo4j/schemas/CoreSchema.cypher` defines 11 node types, 15 relationship types, 12 query patterns
- **Worker**: `Hartonomous.Workers.Neo4jSync` (background service) consumes `Neo4jSyncQueue`, executes Cypher via Neo4j.Driver 5.28+

**Example Explainability Query** (required for GDPR compliance):

```cypher
// Q1: Why was this decision made? (GDPR Article 22 - right to explanation)
MATCH (i:Inference {inference_id: $inference_id})-[:RESULTED_IN]->(d:Decision)
MATCH (d)-[:SUPPORTED_BY]->(ev:Evidence)
MATCH (i)-[r:USED_MODEL]->(m:Model)
RETURN d.output_text,
       d.confidence,
       collect(DISTINCT {model: m.name, weight: r.contribution_weight, confidence: r.individual_confidence}) as models_used,
       collect(DISTINCT {type: ev.type, score: ev.similarity_score, content: ev.content}) as supporting_evidence
```

**Performance**: Neo4j Desktop (HART-DESKTOP Windows), Neo4j Community (HART-SERVER Linux) both deployed per [DEPLOYMENT_ARCHITECTURE_PLAN.md](../DEPLOYMENT_ARCHITECTURE_PLAN.md).

## Key Workflows

### Semantic Search Workflow

```sql
-- 1. Generate query embedding (CLR)
DECLARE @queryEmbedding VECTOR(1998);
SET @queryEmbedding = dbo.fn_ComputeEmbedding('find documentation about CLR deployment', 'text-embedding-3-large');

-- 2. Spatial bounding box filter (R-tree index)
-- Returns ~100 candidates from 1M+ embeddings in O(log n)
WITH SpatialCandidates AS (
    SELECT e.AtomId, e.EmbeddingVector
    FROM dbo.AtomEmbeddings e
    WHERE e.SpatialGeometry.STIntersects(
        dbo.fn_ComputeBoundingBox(@queryEmbedding, @searchRadius)
    ) = 1
)

-- 3. Exact distance refinement (CLR SIMD)
SELECT TOP 10 
    a.AtomId, 
    a.Modality, 
    a.ContentJson,
    dbo.clr_VectorDistance(@queryEmbedding, sc.EmbeddingVector) AS Distance
FROM SpatialCandidates sc
INNER JOIN dbo.Atoms a ON sc.AtomId = a.AtomId
ORDER BY Distance ASC;
```

**Complexity**: O(log n) for spatial filter + O(k × d) for refinement, where k ≪ n (typically k/n ≈ 0.001)

### Autonomous Optimization Workflow

```sql
-- Observation: Slow query detected by Query Store
INSERT INTO dbo.Observations (ObservationType, ObservationJson)
VALUES ('SlowQuery', '{"queryHash": "0x123ABC", "avgDuration": 2500, "threshold": 1000}');

-- Trigger analysis (async via Service Broker)
EXEC dbo.sp_Analyze 
    @observationJson = '{"queryHash": "0x123ABC", "avgDuration": 2500, "threshold": 1000}';

-- Service Broker routes message through OODA loop:
-- 1. sp_Analyze → publishes to HypothesizeQueue
-- 2. sp_Hypothesize → evaluates patterns, publishes to ActQueue
-- 3. sp_Act → creates index in transaction, publishes to LearnQueue
-- 4. sp_Learn → validates improvement, records in AutonomousImprovementHistory

-- Query improvement history
SELECT 
    ActionType, 
    TargetObject, 
    Improvement, 
    Timestamp
FROM dbo.AutonomousImprovementHistory
WHERE ActionType = 'CreateIndex'
ORDER BY Timestamp DESC;
```

### Model Ingestion Workflow

1. **Upload Model** (via API):

   ```http
   POST /api/models/ingest
   Content-Type: multipart/form-data
   
   {
     "modelName": "llama-3-8b",
     "format": "safetensors",
     "file": <binary>
   }
   ```

2. **Decomposition** (`ModelIngestionService`):
   - Parse model structure (layers, attention heads, feed-forward blocks)
   - Extract tensor slices
   - Compute geometry projections for each tensor
   - Persist to `dbo.Models`, `dbo.ModelLayers`, `dbo.TensorAtoms`, `dbo.TensorAtomCoefficients`

3. **Spatial Indexing**:
   - Geometry `SpatialSignature` indexed via R-tree
   - Enables similarity search across model space (find similar layers, reuse tensors)

4. **Activation**:
   - Model registered in `ModelRegistry`
   - Available for T-SQL inference via `clr_RunInference`

## Deployment and Verification

### Database Provisioning

**Unified Script**: `scripts/deploy-database-unified.ps1`

```pwsh
./scripts/deploy-database-unified.ps1 -Server "localhost" -Database "Hartonomous"
```

**What It Does**:

1. Enables CLR integration (`sp_configure 'clr enabled', 1`)
2. Configures FILESTREAM for model weights
3. Enables Service Broker (`ALTER DATABASE SET ENABLE_BROKER`)
4. Executes schema scripts from `sql/tables`, `sql/procedures`, `sql/functions`
5. Deploys `SqlClrFunctions.dll`:
   - Adds trusted assembly (`sp_add_trusted_assembly`)
   - Creates CLR functions/aggregates/types
   - Binds to T-SQL signatures
6. Sets up Service Broker (message types, contracts, queues, services, activation procedures)
7. Runs verification scripts (`sql/verification/*`)

**Options**:

- `-SkipFilestream`: Skip FILESTREAM setup
- `-SkipClr`: Skip CLR assembly deployment
- `-DryRun`: Show SQL commands without executing
- `-ConnectionString`: Override default connection string

### CLR Deployment

See [docs/CLR_GUIDE.md](docs/CLR_GUIDE.md) for detailed CLR deployment instructions.

**Security**: CLR assemblies deployed as `SAFE` where possible. `UNSAFE` assemblies (SIMD intrinsics, file I/O) require:

- Trusted assembly registration (`sp_add_trusted_assembly`)
- `TRUSTWORTHY OFF` (do NOT enable TRUSTWORTHY)
- `PERMISSION_SET = UNSAFE` only for specific assemblies

### EF Core Migrations (Alternative)

```pwsh
dotnet ef database update --project src/Hartonomous.Data/Hartonomous.Data.csproj --connection "Server=localhost;Database=Hartonomous;Integrated Security=true;TrustServerCertificate=true;"
```

**Important**: In database-first architecture, EF Core migrations are **not recommended** for schema changes. Migrations exist for backward compatibility only. Schema modifications should be made in `sql/` scripts and deployed via `deploy-database-unified.ps1`. After SQL schema changes, update EF Core configurations manually or use `dotnet ef dbcontext scaffold` to regenerate entities.

### Production Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for production deployment guide (systemd units, Azure Arc, monitoring setup).

## Performance Characteristics

### Vector Search

- **Brute Force**: O(n × d) where n = vector count, d = dimensions
- **Spatial Index**: O(log n + k × d) where k = candidates after bounding box filter
- **Typical k/n Ratio**: 0.001 (100 candidates from 100K vectors)
- **Speedup**: ~100x for large datasets

### Throughput

- **Embedding Generation** (CLR): ~200 vectors/sec (single core, CPU-only)
- **Vector Search** (with spatial index): ~10K queries/sec
- **Graph Traversal** (3-hop queries): ~50K edges/sec
- **OODA Cycle**: ~1 hypothesis/minute (safe autonomous operation, validation/shadow mode enabled)

### Memory

- **Embeddings**: 1998 dims × 4 bytes = 7.99 KB per vector
- **Spatial Index**: ~20% overhead (1.6 KB per vector)
- **Graph Edges**: 24 bytes per relationship
- **Total**: ~10 KB per indexed embedding with provenance

## Reference Map

- **Source Code**: `src/` (.NET 10 services, infrastructure, domain, CLR packaging)
- **CLR Assembly**: `src/SqlClr` (.NET Framework 4.8.1 SQL CLR implementation)
- **Database Scripts**: `sql/` (tables, procedures, functions, verification) - **Schema Source of Truth**
- **Automation**: `scripts/` (PowerShell deployment, CLR refresh, dependency analysis)
- **Graph Schema**: `neo4j/schemas/CoreSchema.cypher`
- **Deployment**: `deploy/` (systemd units, bootstrap script)
- **Tests**: `tests/` (unit, integration, database validation, end-to-end suites)
  - **Current Status**: 110/110 unit tests passing (~30-40% coverage), 2/28 integration tests passing (missing infrastructure)
  - **Testing Roadmap**: [TESTING_AUDIT_AND_COVERAGE_PLAN.md](../TESTING_AUDIT_AND_COVERAGE_PLAN.md) (184-item plan to 100% coverage)
- **Documentation**:
  - [README.md](../README.md) - Getting started guide
  - [DEPLOYMENT_ARCHITECTURE_PLAN.md](../DEPLOYMENT_ARCHITECTURE_PLAN.md) - Hybrid Arc SQL deployment strategy
  - [DATABASE_DEPLOYMENT_GUIDE.md](../DATABASE_DEPLOYMENT_GUIDE.md) - Database provisioning guide
  - [API.md](../API.md) - REST API reference
  - [TESTING_AUDIT_AND_COVERAGE_PLAN.md](../TESTING_AUDIT_AND_COVERAGE_PLAN.md) - Testing status and coverage plan
  - [IMPLEMENTATION_CHECKLIST.md](../IMPLEMENTATION_CHECKLIST.md) - 226-item implementation plan
  - [VERSION_AND_COMPATIBILITY_AUDIT.md](../VERSION_AND_COMPATIBILITY_AUDIT.md) - Version compatibility matrix
  - [DATABASE_AND_DEPLOYMENT_AUDIT.md](../DATABASE_AND_DEPLOYMENT_AUDIT.md) - Schema inventory and CLR security
  - [CODE_REFACTORING_AUDIT.md](../CODE_REFACTORING_AUDIT.md) - 400+ code quality issues
  - [docs/CLR_DEPLOYMENT.md](docs/CLR_DEPLOYMENT.md) - CLR reference and security
  - [docs/GODEL_ENGINE.md](docs/GODEL_ENGINE.md) - Autonomous compute reference
  - [scripts/CLR_SECURITY_ANALYSIS.md](../scripts/CLR_SECURITY_ANALYSIS.md) - CLR security surface analysis

All architectural claims are traceable to referenced source files and SQL scripts.
